EEG: silent and perceive speech on 30 Spanish sentences
Large Spanish Speech EEG dataset 

Authors
<ul>
  <li>Carlos Valle</li>
  <li>Carolina Mendez-Orellana</li>
  <li>María Rodríguez-Fernández</li>
</ul>


Resources:
<ul>
    <li>Code availaible at: https://github.com/cgvalle/Large_Spanish_EEG</li>
    <li>Publication: Valle, C., Mendez-Orellana, C., Herff, C., & Rodriguez-Fernandez, M. (2024). Identification of perceived sentences using deep neural networks in EEG. Journal of neural engineering, 21(5), 056044. </li>
</ul>

Abstract:
Decoding speech from brain activity can enable communication for individuals with speech disorders. Deep neural networks have shown great potential for speech decoding applications, but the large data sets required for these models are usually not available for neural recordings of speech impaired subjects. Harnessing data from other participants would thus be ideal to create speech neuroprostheses without the need of patient-specific training data.
In this study, we recorded 60 sessions from 56 healthy participants using 64 EEG channels and developed a neural network capable of subject-independent classification of perceived sentences. We found that sentence identity can be decoded from subjects without prior training achieving higher accuracy than mixed-subject models.
The development of subject-independent models eliminates the need to collect data from a target subject, reducing time and data collection costs during deployment. These results open new avenues for creating speech neuroprostheses when subjects cannot provide training data.  


Please contact us at this e-mail address if you have any question: cgvalle@uc.cl
